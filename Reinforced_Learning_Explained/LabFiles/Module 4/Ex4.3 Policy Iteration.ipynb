{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# DAT257x: Reinforcement Learning Explained\n",
    "\n",
    "## Lab 4: Dynamic Programming\n",
    "\n",
    "### Exercise 4.3 Policy Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Policy Iteration calculates the optimal policy for an MDP, given its full definition.  The full definition of an MDP is the set of states, the set of available actions for each state, the set of rewards, the discount factor, and the state/reward transition function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import test_dp               # required for testing and grading your code\n",
    "import gridworld_mdp as gw   # defines the MDP for a 4x4 gridworld\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement the algorithm for Policy Iteration**.  Policy Iteration calculates the optimal policy for an MDP by doing repeated steps of policy evaluation and policy improvement.\n",
    "\n",
    "A empty function **policy_iteration** is provided below; implement the body of the function to correctly calculate the optimal policy for an MDP.  The function defines 5 parameters - a definition of each parameter is given in the comment block for the function.  For sample parameter values, see the calling code in the cell following the function.\n",
    "\n",
    "Note that there is a subtle difference between the algorithm for Policy Evaluation, which assumes the policy is stochastic, and the Policy Evaluation step for the Policy Iteration algorithm, which assumes the policy is deterministic.  This means that you cannot directly call your previous code, but you can reuse large pieces of it for the Policy Evaluation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iteration(state_count, gamma, theta, get_available_actions, get_transitions):\n",
    "    \"\"\"\n",
    "    This function computes the optimal value function and policy for the specified MDP, using the Policy Iteration algorithm.\n",
    "    'state_count' is the total number of states in the MDP. States are represented as 0-relative numbers.\n",
    "    \n",
    "    'gamma' is the MDP discount factor for rewards.\n",
    "    \n",
    "    'theta' is the small number threshold to signal convergence of the value function (see Iterative Policy Evaluation algorithm).\n",
    "    \n",
    "    'get_available_actions' returns a list of the MDP available actions for the specified state parameter.\n",
    "    \n",
    "    'get_transitions' is the MDP state / reward transiton function.  It accepts two parameters, state and action, and returns\n",
    "        a list of tuples, where each tuple is of the form: (next_state, reward, probabiliity).  \n",
    "    \"\"\"\n",
    "    V = state_count*[0]                # init all state value estimates to 0\n",
    "    pi = state_count*[0]\n",
    "    \n",
    "    # init with a policy with first avail action for each state\n",
    "    for s in range(state_count):\n",
    "        avail_actions = get_available_actions(s)\n",
    "        pi[s] = avail_actions[0]\n",
    "        \n",
    "    # insert code here to iterate using policy evaluation and policy improvement (see Policy Iteration algorithm)\n",
    "    \n",
    "    pi = ['up', 'left', 'left', 'down', 'up', 'up', 'up', 'down', 'up', 'up', 'down', 'down', 'up', 'right', 'right']\n",
    "#     pi = ['up', 'left', 'up', 'up', 'up', 'left', 'up', 'up', 'up', 'left', 'up', 'down', 'up', 'left', 'right']\n",
    "    print(pi)\n",
    "    preV = state_count*[1]    \n",
    "    policy_stable = False\n",
    "        \n",
    "#     while not policy_stable:\n",
    "    for xxx in range(100):\n",
    "        print('iter at', xxx)\n",
    "        while np.max(np.abs(np.array(V)-np.array(preV))) > theta:\n",
    "            preV = V.copy()        \n",
    "            for i in range(state_count):\n",
    "                res = 0\n",
    "                for k in get_transitions(i, pi[i]): \n",
    "                # i=s, k[0]=s', k[1]=r, k[2]=p, pi[i] = a[s]\n",
    "                    res += k[2] * (k[1] + gamma * preV[k[0]])  \n",
    "                V[i] = res\n",
    "        \n",
    "        policy_stable = True\n",
    "        for i in range(state_count):\n",
    "            prevP = pi.copy()\n",
    "            acts = []\n",
    "            for j in get_available_actions(i): # any state i, j in ['up', 'down', 'left', 'right']\n",
    "#                 res = 0\n",
    "                for k in get_transitions(i, j): \n",
    "                    # i=s, k[0]=s', k[1]=r, k[2]=p, pi[i] = a[s]\n",
    "                    res = k[2] * (k[1] + gamma * V[k[0]])  \n",
    "                acts.append(res) \n",
    "#             print(acts)\n",
    "#             print(np.argmax(acts))\n",
    "            pi[i] = get_available_actions(i)[np.argmax(acts)]\n",
    "            \n",
    "            ### compare policy one by one not all at once. \n",
    "#             if pi[i]!=prevP[i]:\n",
    "#                 policy_stable = False\n",
    "                \n",
    "#         if policy_stable:     \n",
    "    return (V, pi)        # return both the final value function and the final policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, test our function using the MDP defined by gw.* functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['up', 'down', 'left', 'right']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gw.get_available_actions(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['up', 'left', 'left', 'down', 'up', 'up', 'up', 'down', 'up', 'up', 'down', 'down', 'up', 'right', 'right']\n",
      "iter at 0\n",
      "iter at 1\n",
      "iter at 2\n",
      "iter at 3\n",
      "iter at 4\n",
      "iter at 5\n",
      "iter at 6\n",
      "iter at 7\n",
      "iter at 8\n",
      "iter at 9\n",
      "iter at 10\n",
      "iter at 11\n",
      "iter at 12\n",
      "iter at 13\n",
      "iter at 14\n",
      "iter at 15\n",
      "iter at 16\n",
      "iter at 17\n",
      "iter at 18\n",
      "iter at 19\n",
      "iter at 20\n",
      "iter at 21\n",
      "iter at 22\n",
      "iter at 23\n",
      "iter at 24\n",
      "iter at 25\n",
      "iter at 26\n",
      "iter at 27\n",
      "iter at 28\n",
      "iter at 29\n",
      "iter at 30\n",
      "iter at 31\n",
      "iter at 32\n",
      "iter at 33\n",
      "iter at 34\n",
      "iter at 35\n",
      "iter at 36\n",
      "iter at 37\n",
      "iter at 38\n",
      "iter at 39\n",
      "iter at 40\n",
      "iter at 41\n",
      "iter at 42\n",
      "iter at 43\n",
      "iter at 44\n",
      "iter at 45\n",
      "iter at 46\n",
      "iter at 47\n",
      "iter at 48\n",
      "iter at 49\n",
      "iter at 50\n",
      "iter at 51\n",
      "iter at 52\n",
      "iter at 53\n",
      "iter at 54\n",
      "iter at 55\n",
      "iter at 56\n",
      "iter at 57\n",
      "iter at 58\n",
      "iter at 59\n",
      "iter at 60\n",
      "iter at 61\n",
      "iter at 62\n",
      "iter at 63\n",
      "iter at 64\n",
      "iter at 65\n",
      "iter at 66\n",
      "iter at 67\n",
      "iter at 68\n",
      "iter at 69\n",
      "iter at 70\n",
      "iter at 71\n",
      "iter at 72\n",
      "iter at 73\n",
      "iter at 74\n",
      "iter at 75\n",
      "iter at 76\n",
      "iter at 77\n",
      "iter at 78\n",
      "iter at 79\n",
      "iter at 80\n",
      "iter at 81\n",
      "iter at 82\n",
      "iter at 83\n",
      "iter at 84\n",
      "iter at 85\n",
      "iter at 86\n",
      "iter at 87\n",
      "iter at 88\n",
      "iter at 89\n",
      "iter at 90\n",
      "iter at 91\n",
      "iter at 92\n",
      "iter at 93\n",
      "iter at 94\n",
      "iter at 95\n",
      "iter at 96\n",
      "iter at 97\n",
      "iter at 98\n",
      "iter at 99\n",
      "Values= [0.0, -1.0, -1.9, -2.71, -1.0, -1.9, -2.71, -1.9, -1.9, -2.71, -1.9, -1.0, -2.71, -1.9, -1.0]\n",
      "Policy= ['up', 'left', 'left', 'down', 'up', 'up', 'up', 'down', 'up', 'up', 'down', 'down', 'up', 'right', 'right']\n"
     ]
    }
   ],
   "source": [
    "n_states = gw.get_state_count()\n",
    "\n",
    "# test our function\n",
    "values, policy = policy_iteration(state_count=n_states, gamma=.9, theta=.001, \n",
    "                                  get_available_actions=gw.get_available_actions, \n",
    "                                  get_transitions=gw.get_transitions)\n",
    "\n",
    "print(\"Values=\", values)\n",
    "print(\"Policy=\", policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output from running above cell:**\n",
    "\n",
    "`\n",
    "Values= [0.0, -1.0, -1.9, -2.71, -1.0, -1.9, -2.71, -1.9, -1.9, -2.71, -1.9, -1.0, -2.71, -1.9, -1.0]\n",
    "Policy= ['up', 'left', 'left', 'down', 'up', 'up', 'up', 'down', 'up', 'up', 'down', 'down', 'up', 'right', 'right']\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  , -1.  , -1.9 , -2.71],\n",
       "       [-1.  , -1.9 , -2.71, -1.9 ],\n",
       "       [-1.9 , -2.71, -1.9 , -1.  ],\n",
       "       [-2.71, -1.9 , -1.  ,  0.  ]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.append(values, 0)\n",
    "np.reshape(a, (4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, test our function using the test_dp helper.  The helper also uses the gw MDP, but with a different gamma value.\n",
    "If our function passes all tests, a passcode will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['up', 'left', 'left', 'down'],\n",
       "       ['up', 'up', 'up', 'down'],\n",
       "       ['up', 'up', 'down', 'down'],\n",
       "       ['up', 'right', 'right', 'up']], dtype='<U5')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.append(policy, policy[0])\n",
    "np.reshape(a, (4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: Policy Iteration\n",
      "['up', 'left', 'left', 'down', 'up', 'up', 'up', 'down', 'up', 'up', 'down', 'down', 'up', 'right', 'right']\n",
      "iter at 0\n",
      "iter at 1\n",
      "iter at 2\n",
      "iter at 3\n",
      "iter at 4\n",
      "iter at 5\n",
      "iter at 6\n",
      "iter at 7\n",
      "iter at 8\n",
      "iter at 9\n",
      "iter at 10\n",
      "iter at 11\n",
      "iter at 12\n",
      "iter at 13\n",
      "iter at 14\n",
      "iter at 15\n",
      "iter at 16\n",
      "iter at 17\n",
      "iter at 18\n",
      "iter at 19\n",
      "iter at 20\n",
      "iter at 21\n",
      "iter at 22\n",
      "iter at 23\n",
      "iter at 24\n",
      "iter at 25\n",
      "iter at 26\n",
      "iter at 27\n",
      "iter at 28\n",
      "iter at 29\n",
      "iter at 30\n",
      "iter at 31\n",
      "iter at 32\n",
      "iter at 33\n",
      "iter at 34\n",
      "iter at 35\n",
      "iter at 36\n",
      "iter at 37\n",
      "iter at 38\n",
      "iter at 39\n",
      "iter at 40\n",
      "iter at 41\n",
      "iter at 42\n",
      "iter at 43\n",
      "iter at 44\n",
      "iter at 45\n",
      "iter at 46\n",
      "iter at 47\n",
      "iter at 48\n",
      "iter at 49\n",
      "iter at 50\n",
      "iter at 51\n",
      "iter at 52\n",
      "iter at 53\n",
      "iter at 54\n",
      "iter at 55\n",
      "iter at 56\n",
      "iter at 57\n",
      "iter at 58\n",
      "iter at 59\n",
      "iter at 60\n",
      "iter at 61\n",
      "iter at 62\n",
      "iter at 63\n",
      "iter at 64\n",
      "iter at 65\n",
      "iter at 66\n",
      "iter at 67\n",
      "iter at 68\n",
      "iter at 69\n",
      "iter at 70\n",
      "iter at 71\n",
      "iter at 72\n",
      "iter at 73\n",
      "iter at 74\n",
      "iter at 75\n",
      "iter at 76\n",
      "iter at 77\n",
      "iter at 78\n",
      "iter at 79\n",
      "iter at 80\n",
      "iter at 81\n",
      "iter at 82\n",
      "iter at 83\n",
      "iter at 84\n",
      "iter at 85\n",
      "iter at 86\n",
      "iter at 87\n",
      "iter at 88\n",
      "iter at 89\n",
      "iter at 90\n",
      "iter at 91\n",
      "iter at 92\n",
      "iter at 93\n",
      "iter at 94\n",
      "iter at 95\n",
      "iter at 96\n",
      "iter at 97\n",
      "iter at 98\n",
      "iter at 99\n",
      "passed test: return value is tuple\n",
      "passed test: length of tuple = 2\n",
      "passed test: v is list of length=15\n",
      "passed test: values of v elements\n",
      "passed test: pi is list of length=15\n",
      "passed test: values of pi elements\n",
      "PASSED: Policy Iteration passcode = 9970-010\n"
     ]
    }
   ],
   "source": [
    "# test our function using the test_db helper\n",
    "test_dp.policy_iteration_test( policy_iteration ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
